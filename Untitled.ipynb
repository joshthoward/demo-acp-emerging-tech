{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from ipywebrtc import CameraStream, ImageRecorder\n",
    "import numpy as np\n",
    "import onnxruntime as rt\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3cdae4b5f704647b904bb56b27ea83c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ImageRecorder(image=Image(value=b''), stream=CameraStream(constraints={'facing_mode': 'user', 'audio': False, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "camera_config = {\n",
    "    \"facing_mode\": \"user\",\n",
    "    \"audio\": False,\n",
    "    \"video\": {\"width\": 416, \"height\": 416}\n",
    "}\n",
    "\n",
    "image_recorder = ImageRecorder(stream=CameraStream(constraints=camera_config))\n",
    "image_recorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letterbox_image(image, size):\n",
    "    '''resize image with unchanged aspect ratio using padding'''\n",
    "    iw, ih = image.size\n",
    "    w, h = size\n",
    "    scale = min(w/iw, h/ih)\n",
    "    nw = int(iw*scale)\n",
    "    nh = int(ih*scale)\n",
    "\n",
    "    image = image.resize((nw,nh), PIL.Image.BICUBIC)\n",
    "    new_image = PIL.Image.new('RGB', size, (128,128,128))\n",
    "    new_image.paste(image, ((w-nw)//2, (h-nh)//2))\n",
    "    return new_image\n",
    "\n",
    "def preprocess(img):\n",
    "    model_image_size = (416, 416)\n",
    "    boxed_image = letterbox_image(img, tuple(reversed(model_image_size)))\n",
    "    image_data = np.array(boxed_image, dtype='float32')\n",
    "    image_data /= 255.\n",
    "    image_data = np.transpose(image_data, [2, 0, 1])\n",
    "    image_data = np.expand_dims(image_data, 0)\n",
    "    return image_data\n",
    "\n",
    "img = PIL.Image.open(BytesIO(image_recorder.image.value))\n",
    "image_data = preprocess(img)\n",
    "image_size = np.array([img.size[1], img.size[0]], dtype=np.float32).reshape(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = rt.InferenceSession(\"yolov3-tiny.onnx\")\n",
    "boxes, scores, indices = sess.run(None, {\"input_1\": image_data, \"image_shape\": image_size})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_boxes, out_scores, out_classes = [], [], []\n",
    "for idx_ in indices:\n",
    "    idx_ = idx_[0]\n",
    "    out_classes.append(idx_[1])\n",
    "    out_scores.append(scores[tuple(idx_)])\n",
    "    idx_1 = (idx_[0], idx_[2])\n",
    "    out_boxes.append(boxes[idx_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "draw = ImageDraw.Draw(img)\n",
    "for box, score, class_idx in zip(out_boxes, out_scores, out_classes):\n",
    "    draw.rectangle(((box[0], box[1]), (box[2], box[3])), outline=\"yellow\")\n",
    "    print(class_names[class_idx])\n",
    "    \n",
    "img"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo",
   "language": "python",
   "name": "demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
